[TOC]

# 实时数据落地

原始数据经过实时ETL之后落地hive并且落地hbase，主要有两个作用:

- 存储hive数据用作离线分析经过ETL后的原始数据；存储hbase数据用作实时指标分析经过ETL后的原始数据

- 一份数据作为备份：即可把存储hive数据看做是hbase数据的备份，也可把存储hbase数据看做是hive数据的备份

![Snipaste_2022-11-22_21-08-36](assets\Snipaste_2022-11-22_21-08-36.png)

## 数据落地HDFS

### 异常数据写入HDFS

原始数据实时ETL逻辑处理流程，异常数据落地hdfs，使用StreamingFileSink，指定hdfs路径作为异常数据存储基础路径，以当天日期分区存储hive数据，离线数据的写入是每天加载一次（离线数据是T+1的数据）

```mathematica
1 自定义hiveSink(不用)
    使用jdbc的方式将数据写入到hive数据库中，这种方式效率比较低
2 使用StreamingFileSink(采用)
    流式写入hdfs，吞吐量较高，hive的表结构与hdfs数据的格式要相互匹配（首先在hive中创建表），再将数据写入到hive读取的hdfs的数据路径
    指定分桶的策略：
    (1)DateTimeBucketAssigner：默认的桶分配策略，默认基于时间的分配器，每小时产生一个桶，指定时间格式：yyyy-MM-dd-HH
    (2)BasePathBucketAssigner：将所有的文件存在基本路径的分配器（全局桶）

实现步骤如下：
1 创建StreamingFileSink对象并设置HDFS数据存储路径
2 从解析后的原始数据汇总，筛选出异常数据
  2.1 json格式不正确；缺少必要字段，导致数据格式不正确的原因：
        (1)网络原因，车辆行驶在信号差的地方，数据传输不完整；
        (2)数据传输过程中，数据会传TSP造成数据丢失；
        (3)数据采集终端设备故障，导致数据部分丢失
3 指定异常数据输出的sink为StreamingFileSink
```

自定义Sink的方法虽然没有采用，但是我也将对应的方法写出来了

StreamingAnalysis模块com.lhq.Straming.Sink.ToHiveSink

### 正常数据写入HDFS

正常数据会比异常数据大很多，在项目里面对数据进行处理的时候，减少操作往往意味着减少资源的浪费。所以经常对数据进行批量处理，而不是一条条的处理。所以正常数据落地hdfs会控制每次落地的数据量大小

```mathematica
1 采样相同的方法(StreamingFileSink)把正常数据写入hdfs中
2 正常数据写入HDFS，数据合适转换，字段属性之间按’\t’进行分割
  2.1 自定义toHiveString方法，将所有属性使用制表符连接

正常数据写入HDFS实现步骤：
1 创建StreamingFileSink对象并设置HDFS数据存储路径
2 从解析后的原始数据汇总，过滤错误数据，筛选出正确数据
3 指定正确数据输出的sink为StreamingFileSink
4 设置StreamingFileSink批量处理数据容量
5 写入前把数据格式转换为toHiveString返回的字符串，再写入StreamingFileSink中
```

### HDFS数据映射Hive表

用StreamingFileSink方法将正确数据和错误数据写入到对应的HDFS目录中后，需要创建对应的hive表，并关联hdfs数据到hive表中，以实现原始数据实时ETL结果数据落地Hive需求

实现步骤：

```mathematica
1 分别创建外部分区表：正常数据分区表和错误数据分区表
   外部表：删除表时，不会删除表对应的原始数据
   分区表: 便于后期使用分区进行数据查询；便于hdfs分目录存放数据与hive分区数据对应，便于数据存放管理
2 通过调度工具自动运行shell脚本，实现自动完成关联hive表与hdfs数据
   errordatahive.sh
   rightdatahive.sh
```

## 数据落地HBase

HBase对于数据查询基于rowkey来实现的，所以在数据落地HBase的时候涉及了rowkey的涉及，如果不清楚的可以看项目扩展

### 正常数据写入HBase

自定义sink实现

```mathematica
自定义Sink继承RichSinkFunction类实现
  1.自定义sink，继承RichSinkFunction类
  2.重写方法，实现数据写入hbase逻辑
  3.在KafkaSourceDataTask主任务中调用
```

RichSinkFunction细节：

![Snipaste_2022-11-22_22-27-07](assets\Snipaste_2022-11-22_22-27-07.png)

```mathematica
RichSinkFunction抽象类是我们自定义数据输出需继承的对象，继承了AbstractRichFunction，实现了RinkFunction接口，定义了函数对象的生命周期，open、close方法，拥有不可被序列化的RuntimeContext对象
AbstractRichFunction抽象类:
  1 用户自定义函数抽象存根实现，存根实现指的是指向”RichFunction”实现
  2 定义了函数生命周期方法:初始化(open方法)、对象销毁(close方法)
  3 指定所在函数运行时执行上下文对象的方法
SinkFunction接口:
  1 用户自定义sink函数接口
  2 实现写入获得的记录到自定义sink中
  3 该函数每一条记录会被回调一次
  4 定义Context接口
  5 获得当前执行sink时间
  6 获得当前event水印
  7 获得当前输入记录的timestamp
```

开发实现步骤

StreamingAnalysis模块com.lhq.Streaming.Sink.ToHBaseSink

```properties
1.创建 SrcDataToHBaseSink类继承 RichSinkFunction<ItcastDataObj>
2.创建一个有参数-表名的构造方法
3.重写open方法
  3.1 从上下文获取到全局的参数
  3.2 设置hbase的配置，Zookeeper Quorum集群和端口和TableInputFormat的输入表
  3.3 通过连接工厂创建连接
  3.4 通过连接获取表对象
4.重写close方法
  4.1 关闭hbase 表和连接资源
5. 重写 invoke 方法，将读取的数据写入到 hbase
  5.1 setDataSourcePut输入参数value，返回put对象
6. 实现 setDataSourcePut 方法
  6.1 如何设计rowkey VIN+时间戳翻转
  6.2 定义列簇的名称
  6.3 通过 rowkey 实例化 put
  6.4 将所有的字段添加到put的字段中
```

### 写入HBase的优化

使用BufferedMutator通过mutate方法提交数据到缓冲区

StreamingAnalysis模块com.lhq.Streaming.Sink.ToHBaseSinkOptimize

优化代码：

![Snipaste_2022-11-26_22-57-40](assets\Snipaste_2022-11-26_22-57-40.png)

测试结果看项目测试及注意事项

### Phoenix集成HBase

将写入Hbase表的数据通过Phoenix映射，可以在phoenix中通过使用sql语句操作hbase表，在上面的测试之前我们已经在hbase中创建了对应的表vehicle_rightdata，并且列簇是cf，现在可以根据我放在项目脚本下的Phoenix中运行的脚本，在Phoenix中创建好对应的二级索引表和视图，还有索引

### 车辆常用明细数据

phoenix只适合做明细查询和历史查询，不适合多维度统计，sql优化查询，所以我们从原始数据中抽取常用的车辆指标分析数据落地hbase与phoenix建立关联视图，通过phoenix查询明细，因此行主键(rowKey)、车架号(vin)、终端时间(terminalTime)、存储时间(processTime)

```properties
常用指标:
电量百分比(currentElectricity)、当前电量(remainPower)、百公里油耗(fuelConsumption100km)、发动机速度(engineSpeed)、车辆速度(vehicleSpeed)
```

在hbase中创建车辆明细数据表及视图(项目脚本下Phoenix中运行脚本文件里)

### 车辆明细数据统计

将hbase中vehicle_rightdata_detail表的明细数据映射到phoenix中以后，我们可以实现一些明细的指标的统计

#### 车辆总数统计

- 统计车辆明细总数(某天某时刻明细数据)

  - 每辆车每天采集多条数据，因此需要对车辆进行去重，采集过数据的车辆只计数一次，车辆唯一标识为vin，因此对vin进行去重统计总数即可(数据是真是企业的数据，时间比较久了点)

    ```sql
    select count(distinct("vin")) totalVehicleNum from "itcastsrc_vehicle_detail" where "terminalTime" like '2019-11-20 15%';
    ```

- 统计每天在线的车辆总数

  - 以天为维度统计车辆数，基于“总的采集数据车辆数”统计，增加按天分组

  - 需要用到vin，terminalTime

    ```sql
    select count(1) dayTotalNum, SUBSTR("terminalTime", 0,10)  from "itcastsrc_vehicle_detail" group by SUBSTR("terminalTime", 0,10);
    ```

#### 车辆电量统计

- 统计车辆电量百分比

  - 统计车辆最大、最小电量百分比，需要用到vin,currentElectricity

  - 单位：百分比

    ```sql
    select "vin", max("currentElectricity") as "maxValue", min("currentElectricity") as "minValue" from "itcastsrc_vehicle_detail" where "currentElectricity" is not null group by "vin";
    ```

- 统计当前电量

  - 统计用到的字段remainPower
  - 单位：百分比(已乘以100)
  - 当前电量求平均
  - to_number("value") 把字符串类型或日期类型转换成数值类型

  ```sql
  select "vin", avg(to_number("remainPower")) avgRemainPower from "itcastsrc_vehicle_detail" where "terminalTime" like '2019-11-20%' and "remainPower" is not null group by "vin";
  ```

#### 车辆油耗统计

- 统计车辆百公里油耗

  - 统计用到的字段fuelConsumption100km

  - 统计每辆车的百公里油耗

    - 电动车为何还有油耗

    - 一辆普通的燃油汽车和一辆电动汽车行驶相同的距离，需要的能量是相同的,根据汽车动能计算出行驶百公里耗电量得出油耗

      ```sql
      select distinct("vin") distinctVin, "fuelConsumption100km" from "itcastsrc_vehicle_detail" where "terminalTime" like '2019-11-20%' and "fuelConsumption100km" is not null group by "vin","fuelConsumption100km";
      ```

#### 车辆速度统计

- 统计车辆发动机速度

  - 统计使用字段engineSpeed

  - 求最大、最小、平均车速

    ```sql
    select "vin", max("engineSpeed") maxEngineSpeed, min("engineSpeed") minEngineSpeed, avg(to_number("engineSpeed")) avgEngineSpeed from "itcastsrc_vehicle_detail" where "terminalTime" like '2019-11-20%' and "engineSpeed" is not null group by "vin";
    ```

- 统计车辆速度vehicleSpeed

  - 求最大、最小、平均车速

    ```sql
    select "vin", max("vehicleSpeed") maxVehicleSpeed, min("vehicleSpeed") minVehicleSpeed, avg(to_number("vehicleSpeed")) avgVehicleSpeed from "itcastsrc_vehicle_detail" where "terminalTime" like '2019-11-20%' and "vehicleSpeed" is not null group by "vin";
    ```

    
